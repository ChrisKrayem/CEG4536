{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SExKro-BM3FB",
        "outputId": "2e591deb-927f-442d-d8ef-e8a99454d096"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rHit:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
            "Hit:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Get:3 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Hit:6 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:7 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n",
            "Hit:8 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Hit:10 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Get:11 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [2,734 kB]\n",
            "Fetched 2,991 kB in 5s (658 kB/s)\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "nvidia-cuda-toolkit is already the newest version (11.5.1-1ubuntu1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 49 not upgraded.\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "E: Unable to locate package nvidia-nsight-compute\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "E: Unable to locate package nvidia-nsight-systems\n"
          ]
        }
      ],
      "source": [
        "!apt-get update\n",
        "!apt-get install -y nvidia-cuda-toolkit\n",
        "!sudo apt-get install nvidia-nsight-compute\n",
        "!sudo apt-get install nvidia-nsight-systems"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile task6.cu\n",
        "#include <cuda.h>\n",
        "#include \"cuda_runtime.h\"\n",
        "#include \"device_launch_parameters.h\"\n",
        "#include <stdio.h>\n",
        "#include <cassert>\n",
        "#include <iostream>\n",
        "using namespace std;\n",
        "\n",
        "// Matrix dimensions\n",
        "#define M 512\n",
        "#define K 512\n",
        "#define N 512\n",
        "#define TILE_SIZE 16\n",
        "#define PADDED_TILE_SIZE (TILE_SIZE + 1) // Padding to avoid bank conflicts\n",
        "\n",
        "// Optimized kernel with loop unrolling for matrix multiplication\n",
        "__global__ void matrixMultiplyShared(const float* A, const float* B, float* C, int m, int k, int n) {\n",
        "    __shared__ float tileA[PADDED_TILE_SIZE][PADDED_TILE_SIZE];\n",
        "    __shared__ float tileB[PADDED_TILE_SIZE][PADDED_TILE_SIZE];\n",
        "\n",
        "    int row = blockIdx.y * TILE_SIZE + threadIdx.y;\n",
        "    int col = blockIdx.x * TILE_SIZE + threadIdx.x;\n",
        "\n",
        "    float sum = 0.0f;\n",
        "\n",
        "    // Process tiles of A and B\n",
        "    for (int t = 0; t < (k + TILE_SIZE - 1) / TILE_SIZE; t++) {\n",
        "        // Load shared memory with tiles from A and B\n",
        "        if (row < m && t * TILE_SIZE + threadIdx.x < k)\n",
        "            tileA[threadIdx.y][threadIdx.x] = A[row * k + t * TILE_SIZE + threadIdx.x];\n",
        "        else\n",
        "            tileA[threadIdx.y][threadIdx.x] = 0.0f;\n",
        "\n",
        "        if (col < n && t * TILE_SIZE + threadIdx.y < k)\n",
        "            tileB[threadIdx.y][threadIdx.x] = B[(t * TILE_SIZE + threadIdx.y) * n + col];\n",
        "        else\n",
        "            tileB[threadIdx.y][threadIdx.x] = 0.0f;\n",
        "\n",
        "        __syncthreads();\n",
        "\n",
        "        // Loop unrolling: Unroll loop by 4 (adjust based on profiling feedback)\n",
        "        #pragma unroll 4\n",
        "        for (int i = 0; i < TILE_SIZE; i++) {\n",
        "            sum += tileA[threadIdx.y][i] * tileB[i][threadIdx.x];\n",
        "        }\n",
        "\n",
        "        __syncthreads();\n",
        "    }\n",
        "\n",
        "    // Write the result back to global memory\n",
        "    if (row < m && col < n) {\n",
        "        C[row * n + col] = sum;\n",
        "    }\n",
        "}\n",
        "\n",
        "void verify_result(float* A, float* B, float* C, int n) {\n",
        "    float tmp;\n",
        "    const float epsilon = 1e-4;\n",
        "\n",
        "    for (int i = 0; i < n; i++) {\n",
        "        for (int j = 0; j < n; j++) {\n",
        "            tmp = 0.0f;\n",
        "            for (int k = 0; k < n; k++) {\n",
        "                tmp += A[i * n + k] * B[k * n + j];\n",
        "            }\n",
        "\n",
        "            if (fabs(tmp - C[i * n + j]) > epsilon) {\n",
        "                fprintf(stderr, \"Verification failed at row %d, column %d: CPU = %f, GPU = %f\\n\",\n",
        "                        i, j, tmp, C[i * n + j]);\n",
        "                exit(EXIT_FAILURE);\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    int m = M, k = K, n = N;\n",
        "\n",
        "    size_t sizeA = m * k * sizeof(float);\n",
        "    size_t sizeB = k * n * sizeof(float);\n",
        "    size_t sizeC = m * n * sizeof(float);\n",
        "    float *h_A = (float*)malloc(sizeA);\n",
        "    float *h_B = (float*)malloc(sizeB);\n",
        "    float *h_C = (float*)malloc(sizeC);\n",
        "\n",
        "    for (int i = 0; i < m * k; i++) h_A[i] = 1.0f;\n",
        "    for (int i = 0; i < k * n; i++) h_B[i] = 1.0f;\n",
        "\n",
        "    float *d_A, *d_B, *d_C;\n",
        "    cudaMalloc((void**)&d_A, sizeA);\n",
        "    cudaMalloc((void**)&d_B, sizeB);\n",
        "    cudaMalloc((void**)&d_C, sizeC);\n",
        "\n",
        "    cudaMemcpy(d_A, h_A, sizeA, cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_B, h_B, sizeB, cudaMemcpyHostToDevice);\n",
        "\n",
        "    dim3 threadsPerBlock(TILE_SIZE, TILE_SIZE);\n",
        "    dim3 blocksPerGrid((n + TILE_SIZE - 1) / TILE_SIZE, (m + TILE_SIZE - 1) / TILE_SIZE);\n",
        "\n",
        "    cudaEvent_t start, stop;\n",
        "    cudaEventCreate(&start);\n",
        "    cudaEventCreate(&stop);\n",
        "\n",
        "    cudaEventRecord(start);\n",
        "    matrixMultiplyShared<<<blocksPerGrid, threadsPerBlock>>>(d_A, d_B, d_C, m, k, n);\n",
        "    cudaEventRecord(stop);\n",
        "    cudaEventSynchronize(stop);\n",
        "\n",
        "    float milliseconds = 0;\n",
        "    cudaEventElapsedTime(&milliseconds, start, stop);\n",
        "    printf(\"Kernel Execution Time: %f ms\\n\", milliseconds);\n",
        "\n",
        "    cudaEventDestroy(start);\n",
        "    cudaEventDestroy(stop);\n",
        "\n",
        "    cudaMemcpy(h_C, d_C, sizeC, cudaMemcpyDeviceToHost);\n",
        "    verify_result(h_A, h_B, h_C, n);\n",
        "\n",
        "    printf(\"Matrix Multiplication Successful and Verified!\\n\");\n",
        "\n",
        "    free(h_A);\n",
        "    free(h_B);\n",
        "    free(h_C);\n",
        "    cudaFree(d_A);\n",
        "    cudaFree(d_B);\n",
        "    cudaFree(d_C);\n",
        "\n",
        "    return 0;\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IBui4xtANtqj",
        "outputId": "705c1138-02cb-49c5-ea74-1dd8e9d88c8d"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting task6.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -o task6 task6.cu"
      ],
      "metadata": {
        "id": "_4Ch62ZwN-Kc"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!nvprof ./task6"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MVKcsMNzOSa0",
        "outputId": "ae1deaf4-be07-4c49-ec42-348a540b1358"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==17205== NVPROF is profiling process 17205, command: ./task6\n",
            "Kernel Execution Time: 1.145632 ms\n",
            "Matrix Multiplication Successful and Verified!\n",
            "==17205== Profiling application: ./task6\n",
            "==17205== Profiling result:\n",
            "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
            " GPU activities:   79.26%  979.18us         1  979.18us  979.18us  979.18us  matrixMultiplyShared(float const *, float const *, float*, int, int, int)\n",
            "                   14.20%  175.48us         2  87.741us  87.645us  87.837us  [CUDA memcpy HtoD]\n",
            "                    6.54%  80.766us         1  80.766us  80.766us  80.766us  [CUDA memcpy DtoH]\n",
            "      API calls:   96.84%  96.783ms         3  32.261ms  3.7950us  96.695ms  cudaMalloc\n",
            "                    1.45%  1.4459ms         3  481.95us  245.74us  871.34us  cudaMemcpy\n",
            "                    0.98%  982.12us         1  982.12us  982.12us  982.12us  cudaEventSynchronize\n",
            "                    0.31%  313.36us         3  104.45us  38.071us  158.98us  cudaFree\n",
            "                    0.22%  219.18us         1  219.18us  219.18us  219.18us  cudaLaunchKernel\n",
            "                    0.13%  132.04us       114  1.1580us     135ns  52.363us  cuDeviceGetAttribute\n",
            "                    0.02%  17.093us         2  8.5460us     743ns  16.350us  cudaEventCreate\n",
            "                    0.02%  16.645us         1  16.645us  16.645us  16.645us  cuDeviceGetName\n",
            "                    0.01%  11.770us         2  5.8850us  3.5660us  8.2040us  cudaEventRecord\n",
            "                    0.01%  5.0420us         2  2.5210us     931ns  4.1110us  cudaEventDestroy\n",
            "                    0.00%  4.9800us         1  4.9800us  4.9800us  4.9800us  cuDeviceGetPCIBusId\n",
            "                    0.00%  4.4490us         1  4.4490us  4.4490us  4.4490us  cuDeviceTotalMem\n",
            "                    0.00%  2.3970us         1  2.3970us  2.3970us  2.3970us  cudaEventElapsedTime\n",
            "                    0.00%  1.7030us         3     567ns     215ns  1.2290us  cuDeviceGetCount\n",
            "                    0.00%     989ns         2     494ns     172ns     817ns  cuDeviceGet\n",
            "                    0.00%     430ns         1     430ns     430ns     430ns  cuModuleGetLoadingMode\n",
            "                    0.00%     246ns         1     246ns     246ns     246ns  cuDeviceGetUuid\n"
          ]
        }
      ]
    }
  ]
}