{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e-oAogc32T8d",
        "outputId": "ed61b06c-71c8-4972-a78a-f3b70122e609"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting matrix_multiply_shared_memory.cu\n"
          ]
        }
      ],
      "source": [
        "%%writefile matrix_multiply_shared_memory.cu\n",
        "#include <cuda.h>\n",
        "#include \"cuda_runtime.h\"\n",
        "#include \"device_launch_parameters.h\"\n",
        "#include <stdio.h>\n",
        "\n",
        "//ajoute/\n",
        "#include <cassert>\n",
        "#include <iostream>\n",
        "using namespace std;\n",
        "\n",
        "// Taille des matrices\n",
        "#define M 512\n",
        "#define K 512\n",
        "#define N 512\n",
        "#define TILE_SIZE 16 // Taille d'un bloc partagé\n",
        "\n",
        "// Kernel pour la multiplication matricielle optimisée avec mémoire partagée\n",
        "__global__ void matrixMultiplyShared(const float* A, const float* B, float* C, int m, int k, int n) {\n",
        "    // Matrices partagées pour les blocs\n",
        "    __shared__ float tileA[TILE_SIZE][TILE_SIZE];\n",
        "    __shared__ float tileB[TILE_SIZE][TILE_SIZE];\n",
        "\n",
        "    // Indices du thread dans la grille et le bloc\n",
        "    int row = blockIdx.y * TILE_SIZE + threadIdx.y;\n",
        "    int col = blockIdx.x * TILE_SIZE + threadIdx.x;\n",
        "\n",
        "    float sum = 0.0f;\n",
        "\n",
        "    // Parcourir les sous-matrices de A et B\n",
        "    for (int t = 0; t < (k + TILE_SIZE - 1) / TILE_SIZE; t++) {\n",
        "        // Charger les blocs dans la mémoire partagée\n",
        "        if (row < m && t * TILE_SIZE + threadIdx.x < k)\n",
        "            tileA[threadIdx.y][threadIdx.x] = A[row * k + t * TILE_SIZE + threadIdx.x];\n",
        "        else\n",
        "            tileA[threadIdx.y][threadIdx.x] = 0.0f;\n",
        "\n",
        "        if (col < n && t * TILE_SIZE + threadIdx.y < k)\n",
        "            tileB[threadIdx.y][threadIdx.x] = B[(t * TILE_SIZE + threadIdx.y) * n + col];\n",
        "        else\n",
        "            tileB[threadIdx.y][threadIdx.x] = 0.0f;\n",
        "\n",
        "        __syncthreads(); // Synchronisation des threads pour que tout le bloc soit chargé\n",
        "\n",
        "        // Calcul des produits scalaires pour ce sous-bloc\n",
        "        for (int i = 0; i < TILE_SIZE; i++) {\n",
        "            sum += tileA[threadIdx.y][i] * tileB[i][threadIdx.x];\n",
        "        }\n",
        "\n",
        "        __syncthreads(); // Synchronisation avant de charger les prochains blocs\n",
        "    }\n",
        "\n",
        "    // Écriture du résultat dans la mémoire globale\n",
        "    if (row < m && col < n) {\n",
        "        C[row * n + col] = sum;\n",
        "    }\n",
        "}\n",
        "\n",
        "//verif on CPU\n",
        "void verify_result(float* A, float* B, float* C, int n) {\n",
        "    float tmp;\n",
        "    // for every row\n",
        "    for (int i = 0; i < n; i++) {\n",
        "        //for every col\n",
        "        for (int j = 0; j < n; j++) {\n",
        "            //for every element in the row-col pair\n",
        "            tmp = 0;\n",
        "            for (int k = 0; k < n ; k++) {\n",
        "                tmp += A[i * n + k] * B[k * n + j];\n",
        "            }\n",
        "\n",
        "            //check each result\n",
        "            assert(tmp == C[i * n + j]);\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "// Fonction principale\n",
        "int main() {\n",
        "    int m = M, k = K, n = N;\n",
        "\n",
        "    // Allocation et initialisation des matrices sur le CPU\n",
        "    size_t sizeA = m * k * sizeof(float);\n",
        "    size_t sizeB = k * n * sizeof(float);\n",
        "    size_t sizeC = m * n * sizeof(float);\n",
        "    float *h_A = (float*)malloc(sizeA);\n",
        "    float *h_B = (float*)malloc(sizeB);\n",
        "    float *h_C = (float*)malloc(sizeC);\n",
        "\n",
        "    for (int i = 0; i < m * k; i++) h_A[i] = 1 ;\n",
        "    for (int i = 0; i < k * n; i++) h_B[i] = 1 ;\n",
        "\n",
        "    // Allocation mémoire sur le GPU\n",
        "    float *d_A, *d_B, *d_C;\n",
        "    cudaMalloc((void**)&d_A, sizeA);\n",
        "    cudaMalloc((void**)&d_B, sizeB);\n",
        "    cudaMalloc((void**)&d_C, sizeC);\n",
        "\n",
        "    cudaMemcpy(d_A, h_A, sizeA, cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_B, h_B, sizeB, cudaMemcpyHostToDevice);\n",
        "\n",
        "    // Définir les dimensions des threads et des blocs\n",
        "    dim3 threadsPerBlock(TILE_SIZE, TILE_SIZE);\n",
        "    dim3 blocksPerGrid((n + TILE_SIZE - 1) / TILE_SIZE, (m + TILE_SIZE - 1) / TILE_SIZE);\n",
        "\n",
        "    // Définition des événements pour la mesure du temps\n",
        "    cudaEvent_t start, stop;\n",
        "    cudaEventCreate(&start);\n",
        "    cudaEventCreate(&stop);\n",
        "\n",
        "    // Démarrage de la mesure\n",
        "    cudaEventRecord(start);\n",
        "\n",
        "    // Lancement du kernel\n",
        "    matrixMultiplyShared<<<blocksPerGrid, threadsPerBlock>>>(d_A, d_B, d_C, m, k, n);\n",
        "\n",
        "    // Arrêt de la mesure\n",
        "    cudaEventRecord(stop);\n",
        "    cudaEventSynchronize(stop);\n",
        "\n",
        "    // Calcul de la durée\n",
        "    float milliseconds = 0;\n",
        "    cudaEventElapsedTime(&milliseconds, start, stop);\n",
        "    printf(\"Temps d'exécution du kernel : %f ms\\n\", milliseconds);\n",
        "\n",
        "    // Destruction des événements\n",
        "    cudaEventDestroy(start);\n",
        "    cudaEventDestroy(stop);\n",
        "\n",
        "    // Copier le résultat vers le CPU\n",
        "    cudaMemcpy(h_C, d_C, sizeC, cudaMemcpyDeviceToHost);\n",
        "\n",
        "    printf(\"C[0][0] = %f\\n\", h_C[0]);\n",
        "\n",
        "    //verif result with the CPU\n",
        "    verify_result(h_A, h_B, h_C, n);\n",
        "    cout << \"Matrix Multiplication Successfully Calculated on GPU and Verified by the CPU\" << endl;\n",
        "\n",
        "    // Libération de la mémoire\n",
        "    free(h_A);\n",
        "    free(h_B);\n",
        "    free(h_C);\n",
        "    cudaFree(d_A);\n",
        "    cudaFree(d_B);\n",
        "    cudaFree(d_C);\n",
        "\n",
        "    return 0;\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc matrix_multiply_shared_memory.cu -o matrix_multiply_shared_memory"
      ],
      "metadata": {
        "id": "86E0BEfP2jAo"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!./matrix_multiply_shared_memory"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oy99G3yx2j7f",
        "outputId": "9bf85cde-79db-4a5a-e902-ab45172933b3"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Temps d'exécution du kernel : 0.900704 ms\n",
            "C[0][0] = 512.000000\n",
            "Matrix Multiplication Successfully Calculated on GPU and Verified by the CPU\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvprof ./matrix_multiply_shared_memory"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KcZ_-TSy2mMp",
        "outputId": "9615e666-595a-4858-913e-c0e6d92a1a75"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==15722== NVPROF is profiling process 15722, command: ./matrix_multiply_shared_memory\n",
            "Temps d'exécution du kernel : 0.875360 ms\n",
            "C[0][0] = 512.000000\n",
            "Matrix Multiplication Successfully Calculated on GPU and Verified by the CPU\n",
            "==15722== Profiling application: ./matrix_multiply_shared_memory\n",
            "==15722== Profiling result:\n",
            "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
            " GPU activities:   73.36%  742.38us         1  742.38us  742.38us  742.38us  matrixMultiplyShared(float const *, float const *, float*, int, int, int)\n",
            "                   17.36%  175.64us         2  87.821us  87.325us  88.318us  [CUDA memcpy HtoD]\n",
            "                    9.29%  93.981us         1  93.981us  93.981us  93.981us  [CUDA memcpy DtoH]\n",
            "      API calls:   96.15%  70.824ms         3  23.608ms  3.3880us  70.750ms  cudaMalloc\n",
            "                    1.90%  1.4011ms         3  467.03us  240.86us  830.41us  cudaMemcpy\n",
            "                    1.01%  745.13us         1  745.13us  745.13us  745.13us  cudaEventSynchronize\n",
            "                    0.43%  313.99us         3  104.66us  31.257us  166.36us  cudaFree\n",
            "                    0.26%  189.22us         1  189.22us  189.22us  189.22us  cudaLaunchKernel\n",
            "                    0.17%  127.78us       114  1.1200us     142ns  50.487us  cuDeviceGetAttribute\n",
            "                    0.03%  19.186us         2  9.5930us     716ns  18.470us  cudaEventCreate\n",
            "                    0.02%  12.247us         1  12.247us  12.247us  12.247us  cuDeviceGetName\n",
            "                    0.02%  11.315us         2  5.6570us  3.5040us  7.8110us  cudaEventRecord\n",
            "                    0.01%  5.2560us         1  5.2560us  5.2560us  5.2560us  cuDeviceGetPCIBusId\n",
            "                    0.01%  4.7100us         1  4.7100us  4.7100us  4.7100us  cuDeviceTotalMem\n",
            "                    0.00%  2.7690us         2  1.3840us     915ns  1.8540us  cudaEventDestroy\n",
            "                    0.00%  1.9620us         1  1.9620us  1.9620us  1.9620us  cudaEventElapsedTime\n",
            "                    0.00%  1.4270us         3     475ns     181ns     886ns  cuDeviceGetCount\n",
            "                    0.00%  1.0450us         2     522ns     273ns     772ns  cuDeviceGet\n",
            "                    0.00%     469ns         1     469ns     469ns     469ns  cuModuleGetLoadingMode\n",
            "                    0.00%     245ns         1     245ns     245ns     245ns  cuDeviceGetUuid\n"
          ]
        }
      ]
    }
  ]
}